{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "171d3499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from statistics import mode\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import LancasterStemmer\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input,LSTM,Embedding,Dense,Concatenate,Attention\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1dab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset file for text Summarizer\n",
    "df=pd.read_csv(\"text-generator.csv\",  encoding='cp1252')\n",
    "# Drop the duplicate and na values from the records\n",
    "df.drop_duplicates(subset=['Text'],inplace=True)\n",
    "df.dropna(axis=0,inplace=True)\n",
    "input_data = df.loc[:,'Text']\n",
    "target_data = df.loc[:,'Summary']\n",
    "# df.head()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a1ace17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(661, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5fbd2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null columns (Summary) =  0\n",
      "Null columns (Text) =  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Null columns (Summary) = \", df['Summary'].isnull().sum())\n",
    "print(\"Null columns (Text) = \", df['Text'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b8f635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(661, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edrawmax will not publish or disseminate any i...</td>\n",
       "      <td>ensure compliance with terms of service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>please understand that due to the nature of th...</td>\n",
       "      <td>internet is not completly safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>certain services on the website permit the use...</td>\n",
       "      <td>the process of sharing uploaded files</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cookies and similar technologies tracking tech...</td>\n",
       "      <td>cookies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>information collected from other sources we ma...</td>\n",
       "      <td>other ressources</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  edrawmax will not publish or disseminate any i...   \n",
       "1  please understand that due to the nature of th...   \n",
       "2  certain services on the website permit the use...   \n",
       "3  cookies and similar technologies tracking tech...   \n",
       "4  information collected from other sources we ma...   \n",
       "\n",
       "                                   Summary  \n",
       "0  ensure compliance with terms of service  \n",
       "1           internet is not completly safe  \n",
       "2    the process of sharing uploaded files  \n",
       "3                                  cookies  \n",
       "4                         other ressources  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "737807a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts=[]\n",
    "target_texts=[]\n",
    "input_words=[]\n",
    "target_words=[]\n",
    "contractions=pickle.load(open(\"contractions.pkl\",\"rb\"))['contractions']\n",
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20b88866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(texts):\n",
    "    # Tokenize the text into words \n",
    "    words=word_tokenize(texts.lower())\n",
    "    # Contraction file to expand shortened words\n",
    "#     words= [contractions[w] if w in contractions else w for w in words ]\n",
    "#     words= [w for w in words if w not in stop_words]\n",
    "#     print (words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15f77dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the input records and taret records\n",
    "for in_txt,tr_txt in zip(input_data,target_data):\n",
    "    in_words= in_txt\n",
    "    input_texts+= [' '.join(in_words)]\n",
    "    input_words+= in_words\n",
    "    # Add 'start' at start and 'end' at end of text\n",
    "    tr_words= clean(\"start \"+tr_txt+\" end\")\n",
    "    target_texts+= [' '.join(tr_words)]\n",
    "    target_words+= tr_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7488ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of input words :  39\n",
      "number of target words :  644\n",
      "maximum input length :  347\n",
      "maximum target length :  47\n"
     ]
    }
   ],
   "source": [
    "# Store only unique words from input and target list of words\n",
    "input_words = sorted(list(set(input_words)))\n",
    "target_words = sorted(list(set(target_words)))\n",
    "num_in_words = len(input_words) #total number of input words\n",
    "num_tr_words = len(target_words) #total number of target words\n",
    " \n",
    "# Get the length of the input and target texts which appears most often  \n",
    "max_in_len = mode([len(i) for i in input_texts])\n",
    "max_tr_len = mode([len(i) for i in target_texts])\n",
    " \n",
    "print(\"number of input words : \",num_in_words)\n",
    "print(\"number of target words : \",num_tr_words)\n",
    "print(\"maximum input length : \",max_in_len)\n",
    "print(\"maximum target length : \",max_tr_len)\n",
    "# print(\"maximum target length : \",100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ffba3a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in input_texts:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in target_texts:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "# print(\"text_word_count\",text_word_count)\n",
    "# print(\"summary_word_count\",summary_word_count)\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25c4d627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "\n",
    "def clean_word2vec(text):  \n",
    "    \n",
    "    # 1. Removing html tags\n",
    "    paragraph_text = BeautifulSoup(text,\"lxml\").get_text()\n",
    "    \n",
    "    # 2. Retaining only alphabets.\n",
    "    paragraph_text = re.sub(\"[^a-zA-Z]\",\" \",paragraph_text)\n",
    "    \n",
    "    # 3. Converting to lower case and splitting\n",
    "    word_tokens= paragraph_text.lower().split()\n",
    "    \n",
    "    # 4. Remove stopwords\n",
    "    le=WordNetLemmatizer()\n",
    "    stop_words= set(stopwords.words(\"english\"))     \n",
    "    word_tokens= [le.lemmatize(w) for w in word_tokens if not w in stop_words]\n",
    "    \n",
    "    cleaned_paragraph=\" \".join(word_tokens)\n",
    "    return cleaned_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33c76d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\esi\\pfe\\transpvisback\\transpvisback\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "path_to_word2vec_file = 'license.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "data = []\n",
    "with open(path_to_word2vec_file, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        if line not in {\"\\n\"}:\n",
    "            data.append(clean_word2vec(line))\n",
    "            \n",
    "sentences_text = [[word for word in sentence.split()] for sentence in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e84ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Parameters: -\n",
    "    # sentences : The sentences we have obtained.\n",
    "    # size : The dimesnions of the vector used to represent each word.\n",
    "    # window : The number f words around any word to see the context.\n",
    "    # min_count : The minimum number of times a word should appear for its embedding to be formed or learnt.\n",
    "\n",
    "w2v_model_text=gensim.models.Word2Vec(sentences=sentences_text,\n",
    "#                                  size=300,\n",
    "                                 window=10,\n",
    "                                 min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e22d2e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(495454, 624060)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model_text.train(sentences_text,\n",
    "                epochs=20,\n",
    "                total_examples=len(sentences_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710c99b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_model_text.wv.get_vector('policy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70ca2894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words are :  2700\n"
     ]
    }
   ],
   "source": [
    "# total numberof extracted words.\n",
    "vocab = w2v_model_text.wv.index_to_key\n",
    "print(\"The total number of words are : \",len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1434b172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('diagnose', 0.8197517991065979),\n",
       " ('relation', 0.8082917928695679),\n",
       " ('organisation', 0.7948686480522156),\n",
       " ('generic', 0.7944537997245789),\n",
       " ('renting', 0.7886198163032532),\n",
       " ('rent', 0.7868667244911194),\n",
       " ('store', 0.7858895063400269),\n",
       " ('depend', 0.78386390209198),\n",
       " ('localized', 0.7804555892944336),\n",
       " ('agreed', 0.7769004702568054)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words most similar to a given word.\n",
    "w2v_model_text.wv.most_similar('information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8a6923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64936674"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similaraity b/w two words\n",
    "w2v_model_text.wv.similarity('data','information')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "368818e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of key-value pairs :  2700\n"
     ]
    }
   ],
   "source": [
    "vocab_text=list(w2v_model_text.wv.index_to_key)\n",
    "\n",
    "word_vec_dict_text={}\n",
    "for word in vocab_text:\n",
    "    word_vec_dict_text[word]=w2v_model_text.wv.get_vector(word)\n",
    "print(\"The no of key-value pairs : \",len(word_vec_dict_text)) # should come equal to vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69ca46e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "# now since we will have to pad we need to find the maximum lenght of any document.\n",
    "\n",
    "maxi=-1\n",
    "for i,rev in enumerate(df['Text']):\n",
    "    tokens=rev.split()\n",
    "    if(len(tokens)>maxi):\n",
    "        maxi=len(tokens)\n",
    "print(maxi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3833f746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2701"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "\n",
    "tok_text = Tokenizer()\n",
    "tok_text.fit_on_texts(data)\n",
    "vocab_size_text = len(tok_text.word_index) + 1\n",
    "encd_rev_text = tok_text.texts_to_sequences(data)\n",
    "vocab_size_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "155d2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_txt_len_text = 229 # max lenght of a texte\n",
    "vocab_size_text = len(tok_text.word_index) + 1  # total no of words\n",
    "embed_dim_text = 100 # embedding dimension as choosen in word2vec constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b3a290f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_txt_len_sum=19  # max lenght of a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10dbe861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1615, 229)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "pad_rev_text= pad_sequences(encd_rev_text, maxlen=max_txt_len_text, padding='post')\n",
    "pad_rev_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d613321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now creating the embedding matrix\n",
    "embed_matrix_text=np.zeros(shape=(vocab_size_text,embed_dim_text))\n",
    "for word,i in tok_text.word_index.items():\n",
    "    embed_vector=word_vec_dict_text.get(word)\n",
    "    if embed_vector is not None:  # word is in the vocabulary learned by the w2v model\n",
    "        embed_matrix_text[i]=embed_vector\n",
    "  # if word is not found then embed_vector corressponding to that vector will stay zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b33d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the input and target text into 80:20 ratio or testing size of 20%.\n",
    "x_train,x_test,y_train,y_test=train_test_split(input_texts,target_texts,test_size=0.1,random_state=40)\n",
    "\n",
    "# Train the tokenizer with all the words\n",
    "  # prepare a tokenizer for texts on training data\n",
    "in_tokenizer = Tokenizer()\n",
    "in_tokenizer.fit_on_texts(x_train)\n",
    "  # preparing a tokenizer for summary on training data \n",
    "tr_tokenizer = Tokenizer()\n",
    "tr_tokenizer.fit_on_texts(y_train)\n",
    "\n",
    "# Convert text into sequence of integers where the integer will be the index of that word\n",
    "x_train= in_tokenizer.texts_to_sequences(x_train) \n",
    "y_train= tr_tokenizer.texts_to_sequences(y_train)\n",
    "\n",
    "# Pad array of 0's if the length is less than the maximum length \n",
    "en_in_data= pad_sequences(x_train,  maxlen=max_in_len, padding='post') \n",
    "dec_data= pad_sequences(y_train,  maxlen=max_tr_len, padding='post')\n",
    "\n",
    "\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "# x = np.array(x_train)\n",
    "en_in_data = minmax_scale.fit_transform(en_in_data)\n",
    "# print(en_in_data)\n",
    " \n",
    "# Decoder input data will not include the last word \n",
    "# i.e. 'end' in decoder input data\n",
    "dec_in_data = dec_data[:,:-1]\n",
    "\n",
    "# Decoder target data will be one time step ahead as it will not include the first word i.e 'start'\n",
    "dec_tr_data = dec_data.reshape(len(dec_data),max_tr_len,1)[:,1:]\n",
    "\n",
    "# print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b1f833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return Sequences = True: When the return sequences \n",
    "# parameter is set to True, LSTM produces the hidden \n",
    "# state and cell state for every timestep\n",
    "\n",
    "# Return State = True: When return state = True, \n",
    "# LSTM produces the hidden state and cell state of \n",
    "# the last timestep only\n",
    "\n",
    "# Initial State: This is used to initialize the \n",
    "# internal states of the LSTM for the first timestep\n",
    "\n",
    "# Stacked LSTM: Stacked LSTM has multiple layers of \n",
    "# LSTM stacked on top of each other. This leads to a\n",
    "# better representation of the sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a0cd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def add_prefix(model, prefix: str, custom_objects=None):\n",
    "    '''Adds a prefix to layers and model name while keeping the pre-trained weights\n",
    "    Arguments:\n",
    "        model: a tf.keras model\n",
    "        prefix: a string that would be added to before each layer name\n",
    "        custom_objects: if your model consists of custom layers you shoud add them pass them as a dictionary. \n",
    "    Returns:\n",
    "        new_model: a tf.keras model having same weights as the input model.\n",
    "    '''\n",
    "    \n",
    "    config = model.get_config()\n",
    "    old_to_new = {}\n",
    "    new_to_old = {}\n",
    "    \n",
    "    for layer in config['layers']:\n",
    "        new_name = prefix + layer['name']\n",
    "        old_to_new[layer['name']], new_to_old[new_name] = new_name, layer['name']\n",
    "        layer['name'] = new_name\n",
    "        layer['config']['name'] = new_name\n",
    "\n",
    "        if len(layer['inbound_nodes']) > 0:\n",
    "            for in_node in layer['inbound_nodes'][0]:\n",
    "                in_node[0] = old_to_new[in_node[0]]\n",
    "    \n",
    "    for input_layer in config['input_layers']:\n",
    "        input_layer[0] = old_to_new[input_layer[0]]\n",
    "    \n",
    "    for output_layer in config['output_layers']:\n",
    "        output_layer[0] = old_to_new[output_layer[0]]\n",
    "    \n",
    "    config['name'] = prefix + config['name']\n",
    "    new_model = tf.keras.Model().from_config(config, custom_objects)\n",
    "    \n",
    "    for layer in new_model.layers:\n",
    "        layer.set_weights(model.get_layer(new_to_old[layer.name]).get_weights())\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea85223f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2701"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09aa4a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"v2_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " v2_input_0 (InputLayer)        [(None, 347)]        0           []                               \n",
      "                                                                                                  \n",
      " v2_en_embedding (Embedding)    (None, 347, 100)     270100      ['v2_input_0[0][0]']             \n",
      "                                                                                                  \n",
      " v2_LSTM1 (LSTM)                [(None, 347, 500),   1202000     ['v2_en_embedding[0][0]']        \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " v2_input_1 (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " v2_LSTM2 (LSTM)                [(None, 347, 500),   2002000     ['v2_LSTM1[0][0]']               \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " v2_embedding (Embedding)       (None, None, 100)    270100      ['v2_input_1[0][0]']             \n",
      "                                                                                                  \n",
      " v2_LSTM3 (LSTM)                [(None, 347, 500),   2002000     ['v2_LSTM2[0][0]']               \n",
      "                                 (None, 500),                                                     \n",
      "                                 (None, 500)]                                                     \n",
      "                                                                                                  \n",
      " v2_lstm (LSTM)                 [(None, None, 500),  1202000     ['v2_embedding[0][0]',           \n",
      "                                 (None, 500),                     'v2_LSTM3[0][1]',               \n",
      "                                 (None, 500)]                     'v2_LSTM3[0][2]']               \n",
      "                                                                                                  \n",
      " v2_attention (Attention)       (None, None, 500)    0           ['v2_lstm[0][0]',                \n",
      "                                                                  'v2_LSTM3[0][0]']               \n",
      "                                                                                                  \n",
      " v2_concat_layer1 (Concatenate)  (None, None, 1000)  0           ['v2_lstm[0][0]',                \n",
      "                                                                  'v2_attention[0][0]']           \n",
      "                                                                                                  \n",
      " v2_dense (Dense)               (None, None, 645)    645645      ['v2_concat_layer1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,593,845\n",
      "Trainable params: 7,593,845\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# import mdn\n",
    "\n",
    "K.clear_session() \n",
    "latent_dim = 500\n",
    "\n",
    "# Encoder \n",
    "# Create input object of total number of encoder words\n",
    "en_inputs = Input(shape=(max_in_len,),name='input_0')\n",
    "\n",
    "# en_embedding = Embedding(num_in_words+1, latent_dim, name='en_embedding')(en_inputs) \n",
    "en_embedding = Embedding(vocab_size_text, \n",
    "                         embed_dim_text, \n",
    "                         name='en_embedding', \n",
    "                         input_length=max_txt_len_text,\n",
    "                         embeddings_initializer=tf.keras.initializers.Constant(embed_matrix_text)\n",
    "                        )(en_inputs) \n",
    "# Embedding(input_dim=vocab_size,output_dim=embed_dim,input_length=max_txt_len,embeddings_initializer=Constant(embed_matrix))\n",
    "\n",
    "# Create 3 stacked LSTM layer with the shape of hidden dimension for text summarizer using deep learning\n",
    "# LSTM 1\n",
    "en_lstm1= LSTM(latent_dim, return_state=True, return_sequences=True,name='LSTM1') \n",
    "en_outputs1, state_h1, state_c1= en_lstm1(en_embedding) \n",
    " \n",
    "# LSTM2\n",
    "en_lstm2= LSTM(latent_dim, return_state=True, return_sequences=True,name='LSTM2') \n",
    "en_outputs2, state_h2, state_c2= en_lstm2(en_outputs1) \n",
    " \n",
    "# LSTM3\n",
    "en_lstm3= LSTM(latent_dim,return_sequences=True,return_state=True,name='LSTM3')\n",
    "en_outputs3 , state_h3 , state_c3= en_lstm3(en_outputs2)\n",
    " \n",
    "# Encoder states\n",
    "en_states= [state_h3, state_c3]\n",
    "\n",
    "# Decoder. \n",
    "dec_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(vocab_size_text, \n",
    "                          embed_dim_text,\n",
    "                          input_length=max_txt_len_sum,\n",
    "                          embeddings_initializer=tf.keras.initializers.Constant(embed_matrix_text)\n",
    "                         ) \n",
    "dec_embedding = dec_emb_layer(dec_inputs) \n",
    " \n",
    "# Initialize decoder's LSTM layer with the output states of encoder\n",
    "dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "dec_outputs, *_ = dec_lstm(dec_embedding,initial_state=en_states) \n",
    "\n",
    "# Attention layer\n",
    "attention =Attention()\n",
    "attn_out = attention([dec_outputs,en_outputs3])\n",
    " \n",
    "# Concatenate the attention output with the decoder outputs\n",
    "merge=Concatenate(axis=-1, name='concat_layer1')([dec_outputs,attn_out])\n",
    "\n",
    "# Dense layer (output layer)\n",
    "dec_dense = Dense(num_tr_words+1, activation='softmax')\n",
    "# m = 32 # number of gaussian models to build\n",
    "# dec_dense = mdn.MDN(num_tr_words+1,m)\n",
    "dec_outputs = dec_dense(merge) \n",
    "\n",
    "# Model class and model summary for text Summarizer\n",
    "new_model = Model([en_inputs, dec_inputs], dec_outputs) \n",
    "model = add_prefix(new_model, 'v2_')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b48b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "# optimizer = tf.keras.optimizers.Adam(lr=0.000001)\n",
    "# optimizer = 'sgd'\n",
    "# optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"] \n",
    "\n",
    "model.compile( \n",
    "    optimizer=optimizer, \n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"] \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b60b7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95521216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "9/9 [==============================] - 223s 24s/step - loss: 2.8566 - accuracy: 0.6838 - val_loss: 0.6246 - val_accuracy: 0.8938\n",
      "Epoch 2/15\n",
      "9/9 [==============================] - 212s 24s/step - loss: 0.5805 - accuracy: 0.8988 - val_loss: 0.5897 - val_accuracy: 0.8960\n",
      "Epoch 3/15\n",
      "9/9 [==============================] - 212s 24s/step - loss: 0.5660 - accuracy: 0.8995 - val_loss: 0.5946 - val_accuracy: 0.8982\n",
      "Epoch 4/15\n",
      "9/9 [==============================] - 197s 22s/step - loss: 0.5425 - accuracy: 0.9016 - val_loss: 0.5873 - val_accuracy: 0.8935\n",
      "Epoch 5/15\n",
      "9/9 [==============================] - 202s 22s/step - loss: 0.5401 - accuracy: 0.9029 - val_loss: 0.5612 - val_accuracy: 0.9033\n",
      "Epoch 6/15\n",
      "9/9 [==============================] - 207s 23s/step - loss: 0.5032 - accuracy: 0.9099 - val_loss: 0.5562 - val_accuracy: 0.9101\n",
      "Epoch 7/15\n",
      "9/9 [==============================] - 205s 23s/step - loss: 0.4919 - accuracy: 0.9095 - val_loss: 0.5523 - val_accuracy: 0.9043\n",
      "Epoch 8/15\n",
      "9/9 [==============================] - 208s 23s/step - loss: 0.4749 - accuracy: 0.9139 - val_loss: 0.5466 - val_accuracy: 0.9123\n",
      "Epoch 9/15\n",
      "9/9 [==============================] - 216s 24s/step - loss: 0.4564 - accuracy: 0.9156 - val_loss: 0.5462 - val_accuracy: 0.9083\n",
      "Epoch 10/15\n",
      "9/9 [==============================] - 211s 23s/step - loss: 0.4468 - accuracy: 0.9164 - val_loss: 0.5368 - val_accuracy: 0.9134\n",
      "Epoch 11/15\n",
      "9/9 [==============================] - 216s 24s/step - loss: 0.4270 - accuracy: 0.9191 - val_loss: 0.5364 - val_accuracy: 0.9127\n",
      "Epoch 12/15\n",
      "9/9 [==============================] - 213s 24s/step - loss: 0.4174 - accuracy: 0.9203 - val_loss: 0.5386 - val_accuracy: 0.9145\n",
      "Epoch 13/15\n",
      "9/9 [==============================] - 211s 23s/step - loss: 0.4031 - accuracy: 0.9206 - val_loss: 0.5378 - val_accuracy: 0.9149\n",
      "Epoch 14/15\n",
      "9/9 [==============================] - 213s 24s/step - loss: 0.3884 - accuracy: 0.9234 - val_loss: 0.5344 - val_accuracy: 0.9159\n",
      "Epoch 15/15\n",
      "9/9 [==============================] - 214s 24s/step - loss: 0.3772 - accuracy: 0.9230 - val_loss: 0.5393 - val_accuracy: 0.9174\n"
     ]
    }
   ],
   "source": [
    "history=model.fit( \n",
    "    [en_in_data, dec_in_data],\n",
    "    dec_tr_data, \n",
    "    batch_size=64, \n",
    "    epochs=15, \n",
    "    validation_split=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "f9a317ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0d27ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_6_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s\\assets\n"
     ]
    }
   ],
   "source": [
    "#Save model\n",
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56779e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAosUlEQVR4nO3de5zcdX3v8ddnZnZ39prL7ua6hEQS7pdEY4oiPqqIBKqg9VSB0mqPR+w56LHWesRzLFV6OTxqH15orRZ7OPioAkWsii1IAKH0VKiEkCAJkISLZDb3ZDZ7m73MzOf88fvNZrKZzU7YmZ3dmffz8ZjH/K6zn91H8v3M73s1d0dERGS8SKUDEBGRmUkJQkREClKCEBGRgpQgRESkICUIEREpKFbpAEqlo6PDly9fXukwRERmlaeffvqgu3cWOlc1CWL58uVs3Lix0mGIiMwqZvaric6piklERApSghARkYKUIEREpCAlCBERKUgJQkREClKCEBGRgpQgRESkoKoZByEiMpOkM1kO9A+z58gQ+44Msbd3iOTgKFEzYlEjGjFikfz3yNH96ATHw/fo2H6EaMRobohyantzyX8HJQgRkZM0MJxmb+/Rgn/PkSH29Q6xN9zfe2SIg/3DZKdpuZ3Vp8zlRzdcVPLPVYIQkaqSzToZd7LuZLOQcSeTdTx8z+Qdz2aD6zLhe9Yhk3VGM1kO9A2PFfb5Bf/e3iH6htLH/dzWeIzFc+IsbItzxsLWYHtOnEVtwbHFc+LMa6rHgXQ2SybrpLNOJhO+Z33seGZsP/89SzpT+HhbvK4sf0slCBGZNu7OcDrL4EiGgeE0AyNpBoYzDI6kg/3cdu58uN8/nB67J//eweEMI5nsMYV7qUUMOlsbWNQWZ0VHM289rX2s4F+U995UX3xxGo1ESx5nOShBiMiUuDt9w2n29w6zv3eIfX1D7OsdZn/vMPv6htjfO8T+vmEOD4wwOJIpuhA3g+b6GM0NUZrrYzQ1RGmqj9HZ2sCp7U0018dorI/SEIsQiRgRg6gZkYiNvUfMiEYI34P93PloBMxy23bMZ8SiETpa6lk0J05nSwOxaG3251GCEJEJ9Q+n2dcb1K/v7x1mf1j4j99PjWaOu7e5PsrCtjgL2hq4oGsu85vraQ4L+ZaGGE31UZobYsGrPjje3BAeq48Rr4tgZhX4rWeQbAaG+8JX7wTbfdDcCes+VvIfrwQhMgu5OwMjGYZGMwynswzn3vO2R3L76QLXpDMMjx57Pnd9/3CaA31BEhgcOb7gb8oV/K0NnNc1l3e1NowlggWtcRa2NbCgLU5LQw0WL5k0jA7AaApGwvfRweA1Er6PL9yHeo8/lnuNDhT3c5e9VQlCpFq4O6nRDL2pNL1Do/SmRjmSGg230/TmbY8dz50Lr59KdXssYjTEIjTUBVU0wStKQ12EeF2Uc5a08c4zFwSFfWtQ+OeSQktDrPLf7N1hpB9SSUiPQDYNngnes5nwVeDYMftp8Oyx+/nHxgr1VF6hP3i0wB9/fmQQsqMn8UsYNLRBQ2vwirdB03yYd2p4LO/cMa+2Y8/Vt0CkPFVgShAiJZbNOolkiu37+tixv58d+/s40DccFvpHC//RzIlL+Kb6KG3xOtoaY7TF61jQGmfVgjra4jHaGutojcdorIuOFexjhXwsEu5Hx47V55JAXYT6aGTiOvW+vZB8FSIOsQxEMxAbhWgEYhEwIAtEYkEjwVSlR2CoJyjoU+H72H6hY3n72eN7EpWcRaG+GeqaoK4x3G4M9hvnQ314vK75+PN1TeH5cdu5wr2+uTR/wzJSghB5nY5LBPv62L6/j537+xkazQJQzyjvbnmFFS319DatIDN/EW2NdbQ11jGnse6YBDAnPN4Wj9Ear6M+VsaGUXdIvgJ7noW9z8KeLcH2wP4iP8Ag1gDRBojVT/DeANH6o+/ZNAwdObagn6wKJT4H4nOhcR40zoU5XXn74bFYY/ANOhILCvRIDCLR4HXMfqzwMYuM2w/vrWsKfpcapgQhMoliEgHAorY4qxa28F/eOIe3+SbOOPL/mLvncWxkAHoIXnXN0H4adKyChlXQuBI6VkL7yuBbZTlk0nBwe5AE9j4bJoVfwvCR4HwkBp1nwsp3weLzoX1VUBWTHobMSPg+HHzbP+Y9d36owLHwfWTg6H4kGnzrnrsMFl9wbMGfe4/n7cfnBPdIxShByKzifXvZ/+zD9OzaSm/bGfR2rGa0adExUxDEwi6Lx7znpjewo1MURCIc8x4140hqtOhEcO26Uzl9YQurFrRwRt1eWl7ZANt/Cs/+R1CP3boYzvstOP1yqIvDwR1w6CU4tAMSG+G5fwLyqplaFweJon1lkEDaVwXJZO6pEC3yv+poCvZtg71bjj4V7N8WFOIQfNtedC6c95+CZLDofFhwdhCfyDjmPk1jwcts7dq1rjWpq9DQEXpfeIwDz26gufvfWTT8ynGXJLyDzdmVPJNdyabsKrb6ckaY+sjSXCJYtaA1SAQLW1m5oIU5jXXBt/LXnggSwov3w+GXw5vOhzMuh9PXw+LVJ248HB0KqnkO7giSxsGd4fuOoI49J1IH898QJo6VQeLoWBVUtyRfPZoI9j4LB14Mvv1D8A180fnBt/XFFwTb7SuLTzZSE8zsaXdfW/CcEoTMKKNDDL/8c/Zu2UDsV4+zaOB5omRJeT2b7Uz2tv8a8TPeyYoz30Rzz/PU791Ew95NNO1/hvr+BADZSD0D88/mSPtqjrSvJjnvAvrji8kC6WwwvUL+e8adTCZLOuu0NMRYtbCFlQtag0SQb+gI7HwYXnwAdjwUFOLReljx9qNJYU5Xaf4OA4eOJotDO4PXwR1BIirUU6Z1cZgMzj+aFOYum/GNoFJ5ShAyc2XSZLqfYd+WB8m89BgLezZTzyhpj7DFV/KrOWuxN/w6p635dc5ZtoBo5AQFXu8e6N4Iiadg11Ow+xlIp4JzLYugay10vRlOWRd8u69vmjy+w6+ETwkPwK/+PWhobWqHVZcFSeG0d5Sv7aCQTBqOvBY8bRx5DeYuD5JCy4Lpi0GqihKEzBzu+P5tHH7uYQZf/BkdB5+iMRv0ZHk+u4wXGtcweurbWXrBJbxx1TIa66fQSJkZhX1bg4SRe+Wqgiwa1MV3rQuTxpth3oqg7aD76aDa6MWfwoHng+s7zwyeEM64Ikg0ajyVKqEEIZWV/BX9LzxCz9aHmbP3CVrThwF4NbuQLXXn07/kItrPexdvPvt02lsayhvLwMGggTiXMLqfDgZcQfBkgMHgwSCBnPrWICGcsT5oAxCpQidKEGVtrTKz9cDXgSjw9+5+y7jzpwK3A53AYeA6d0+E5z4MfCG89M/c/TvljFWKl85kGRjJzcB57Myaudk5Yz0vc2riJ6zc/1PahxO0ACmfw+N2Hgc7L6T17Hex5rzzubK9aXpH5TZ3BAX+GeuD/WwGDrxwtFoqOwqr3g0rLwm6WorUsLI9QZhZFNgOXAokgKeAa9x9W9413wf+2d2/Y2bvBH7P3X/HzOYDG4G1BP0Anwbe5O7JiX6eniCKk8k6PYMjJAdHODwwyuGBEQ4PBPu9Q6N5hfyx0yvnT7c8nM4W/OxWBvmN6JN8IPo4b45sJ+vGk5zL9jkXUb/qHZx1/jrO65pbszNjisxElXqCWAfsdPeXwyDuBq4CtuVdczbwh+H2o8CPwu3LgIfc/XB470PAeuCuMsY76+SmWU7mFfKH+o8W/smBEQ4PjoydPzw4wpHUKBN9J6iPRY7OshlOr9wcTq+cv9+cNxNnUx0sS/6CU177EfN3bSCSGSY9byVD53+B2AUf4q3zl/HW6f2ziEiJlDNBLAV25e0ngF8bd80W4DcJqqHeD7SaWfsE9y4tX6il5+68dKCf3qE0I+FMmSPpLCOZYPbMkbzZM0cy2WP386499ppg1s3B4cxYwZ+eYMa2uqgxv7meeU31zG+u56wlbcwPt+c31zOvuZ75TfXMa64buy5edxINr/tfgC13wLP3QN+eYFTsmutg9bXElr6JmLpXisx6lR4x80fA35jZR4DHgW7g+PmFJ2Bm1wPXAyxbtqwc8b1uP3thPx/9zslVecUiRn3MmB8dYlGsj85IPx3WR3ukj/nWy3zvZR5HiESiJNtX0n/amYy0n0V83hLaWxqOKfTLMuPm4GH45b2w5c6gC6lFYdWlsP6WoMtnrMwNzCIyrcqZILqBU/L2u8JjY9x9N8ETBGbWAnzA3XvMrBv49XH3Pjb+B7j7bcBtELRBlDD2Kdu+L+gZc9t1b2SuDdCYTtI42kPjaJKG4SR1I4epSx0iNnSI6NAhIoOHsMFDQS+b7CgUmjW4rhma24O+8Hsfgr3h8cb5sPAcWHhu+H42dJ5VXD//yWRGYccG2HwnbH8wiG3heXDZXwTTSKj/vUjVKmcjdYygkfoSgsTwFHCtu2/Nu6YDOOzuWTP7cyDj7jeFjdRPA28ML91E0Eh9eKKfN22N1NlsMAvl4MGgMM+9528PHmTvnm6iQ4fojPRPPC1xQ1vQtbK5A5o6gsK/qSNvv/PYY3WNR+8dPBzMsbNvK+x7Lph/Z/+2YI56ACyYx2fhObDgnDBxnBPM6zPZ3PHuwfQNW+6CX34fBg8FsZz3QVh9DSw6ryR/ShGpvIo0Urt72sw+ATxI0M31dnffamY3Axvd/T6Cp4T/bWZOUMV0Q3jvYTP7U4KkAnDziZLDlGSzQQE4cCCvgD80rsAPzw8chNThYDBVIfE5Y4V5ty3iQMNK1q87N6/Qz08GHVOrkmmaD8vfFrzyf5fkK2HS2Ar7twazdm67j7FJ4eqagyeM3BPHgrOD/cZ5wVoAz94TJIb924JpJM64HC64Nuj2GZ36/EYiMntooFzvHvjKmQVOWFBoFvp239x5fGHf1H5MAXrpV/6VN3Q283e/UzAxT6/h/qCvfy5x5J468ieEa10M/fuC5Ld0bfCkcM5vBolIRKpWxQbKzQrNHXDFX40r8DuD5PA6Z710D9YPuHhVZ4mDfZ0aWsJ5iPL+DbhD7+6wmiqsoprTBRdcA52nVy5WEZkxlCCidSVf7Ds5OEpqNMPSeY2TX1wpZjBnafBadWmloxGRGUhDWsugOxnMINo1kxOEiMgklCDKIJEMehItnasEISKzlxJEGXT3BE8Qp8wrwTgEEZEKUYIog0QyRUtDjLZGNfGIyOylBFEGiWSKpXMbp3caaxGRElOCKIPunpQaqEVk1lOCKINEcnBmd3EVESmCEkSJ9Q6N0jeU1hOEiMx6ShAllhsDsXSuejCJyOymBFFiiVyC0BOEiMxyShAl1h0OklMVk4jMdkoQJZZIpojXRWhvrq90KCIiU6IEUWLdPSmWaAyEiFQBJYgSC8ZAqIFaRGY/JYgSy42iFhGZ7ZQgSmhwJM3hgRE1UItIVVCCKKHdPVoHQkSqhxJECe0aGySnBCEis58SRAkdXUlOjdQiMvspQZRQIpmiLmosaG2odCgiIlOmBFFCuTEQkYjGQIjI7KcEUULdyUG1P4hI1VCCKCGNgRCRaqIEUSLD6Qz7+4bVQC0iVUMJokT29AwBmuZbRKqHEkSJJDQGQkSqjBJEiXT3aB0IEakuShAlkkimiBgsmhOvdCgiIiWhBFEi3ckUi+c0UhfVn1REqoNKsxJJ9KiLq4hUFyWIEulOptSDSUSqSlkThJmtN7MXzWynmd1Y4PwyM3vUzJ4xs2fN7Irw+HIzS5nZ5vD1rXLGOVXpTJa9vUNqoBaRqhIr1webWRT4BnApkACeMrP73H1b3mVfAO5x92+a2dnA/cDy8NxL7r66XPGV0p4jQ2SyriomEakq5XyCWAfsdPeX3X0EuBu4atw1DrSF23OA3WWMp2y6w4WCVMUkItWknAliKbArbz8RHsv3ReA6M0sQPD18Mu/cirDq6V/N7OJCP8DMrjezjWa28cCBAyUM/eRoHQgRqUaVbqS+BrjD3buAK4B/MLMIsAdY5u5rgD8E7jSztvE3u/tt7r7W3dd2dnZOa+D5cqOoF2sMhIhUkXImiG7glLz9rvBYvo8C9wC4+xNAHOhw92F3PxQefxp4CTi9jLFOSXfPIAtaG4jXRSsdiohIyZQzQTwFrDKzFWZWD1wN3DfumteASwDM7CyCBHHAzDrDRm7M7A3AKuDlMsY6Jd096uIqItWnbAnC3dPAJ4AHgecJeittNbObzezK8LLPAB8zsy3AXcBH3N2BtwPPmtlm4F7g9939cLlinSqtAyEi1ahs3VwB3P1+gsbn/GM35W1vAy4qcN8PgB+UM7ZSyWad3T0pLj93caVDEREpqUo3Us96+/uGGc24qphEpOooQUyRpvkWkWqlBDFFuS6uXWqDEJEqowQxRWMryekJQkSqjBLEFHX3pJjfXE9TfVnb+0VEpp0SxBSpi6uIVCsliCnqTg4qQYhIVVKCmAJ3p7snpR5MIlKVlCCm4NDACEOjWTVQi0hVUoKYAk3zLSLVTAliCsYWClIbhIhUISWIKUgkg1HUqmISkWo0aYIws/eGi/jION3JFK3xGHMa6yodiohIyRVT8H8I2GFmf2lmZ5Y7oNlEYyBEpJpNmiDc/TpgDcGqbneY2RPhWtCtZY9uhgu6uKqBWkSqU1FVR+7eS7Bwz93AYuD9wCYz+2QZY5vR3J3upMZAiEj1KqYN4koz+yHwGFAHrHP3y4ELCFaEq0m9qTR9w2lVMYlI1SpmhrkPAF9198fzD7r7oJl9tDxhzXwJrQMhIlWumATxRWBPbsfMGoGF7v6quz9SrsBmum5N8y0iVa6YNojvA9m8/Ux4rKaNrQOhKiYRqVLFJIiYu4/kdsLt+vKFNDt096RorIsyv7nm/xQiUqWKSRAHzOzK3I6ZXQUcLF9Is0MiOcjSeY2YWaVDEREpi2LaIH4f+J6Z/Q1gwC7gd8sa1Sygab5FpNpNmiDc/SXgQjNrCff7yx7VLNCdTHFB19xKhyEiUjZFLaRsZr8BnAPEc1Uq7n5zGeOa0QaG0yQHR9WDSUSqWjED5b5FMB/TJwmqmH4LOLXMcc1ouWm+Nc2GiFSzYhqp3+ruvwsk3f1LwFuA08sb1sw2Ns23uriKSBUrJkEMhe+DZrYEGCWYj6lmHV1JTglCRKpXMW0QPzGzucCXgU2AA98uZ1AzXaInRX00QmdLQ6VDEREpmxMmiHChoEfcvQf4gZn9MxB39yPTEdxMlUimWDI3TiSiMRAiUr1OWMXk7lngG3n7w7WeHIBwmm81UItIdSumDeIRM/uAacjwmO4erSQnItWvmATxcYLJ+YbNrNfM+syst5gPN7P1Zvaime00sxsLnF9mZo+a2TNm9qyZXZF37vPhfS+a2WVF/0ZlNjSa4UDfsMZAiEjVK2Yk9etaWtTMogTVU5cCCeApM7vP3bflXfYF4B53/6aZnQ3cDywPt68mGJy3BHjYzE5398zriaWUdveoB5OI1IZJE4SZvb3Q8fELCBWwDtjp7i+Hn3M3cBWQnyAcaAu35wC7w+2rgLvdfRh4xcx2hp/3xGTxlpum+RaRWlFMN9fP5m3HCQrqp4F3TnLfUoKJ/XISwK+Nu+aLwIZwbetm4F159z457t6l43+AmV0PXA+wbNmyScIpjbFR1PPVSC0i1W3SNgh3f2/e61LgXCBZop9/DXCHu3cBVwD/EHatLYq73+bua919bWdnZ4lCOrHuZIpoxFjYqjEQIlLdipqsb5wEcFYR13UDp+Ttd4XH8n0UWA/g7k+YWRzoKPLeikgkB1nUFicWLTqPiYjMSsW0Qfw1QVsBBE8cqwlGVE/mKWCVma0gKNyvBq4dd81rwCXAHWZ2FkEV1gHgPuBOM/sKQSP1KuAXRfzMstM6ECJSK4p5gtiYt50G7nL3f5/sJndPm9kngAeBKHC7u281s5uBje5+H/AZ4Ntm9mmCJPQRd3dgq5ndQ9CgnQZumAk9mCCoYrrwtPZKhyEiUnbFJIh7gaFcAW1mUTNrcvfByW509/sJuq7mH7spb3sbcNEE9/458OdFxDdtRjNZ9vYO0aUeTCJSA4oaSQ3kl4iNwMPlCWdm23tkiKxrHQgRqQ3FJIh4/jKj4XZNlpC7cutAqA1CRGpAMQliwMzemNsxszcBqfKFNHNpHQgRqSXFtEH8AfB9M9tNsOToIoIlSGtOd08KM1g8RwlCRKpfMXMxPWVmZwJnhIdedPfR8oY1MyWSKRa0NlAf0xgIEal+k5Z0ZnYD0Ozuz7n7c0CLmf238oc282gdCBGpJcV8Ff5YuKIcAO6eBD5WtohmsETPoCbpE5GaUUyCiOYvFhRO411fvpBmpkzW2dMzpB5MIlIzimmk/inwj2b2d+H+x4EHyhfSzLS/b4h01tWDSURqRjEJ4nMEU2r/frj/LEFPppqidSBEpNYUM913FvgP4FWCtSDeCTxf3rBmnqNjINRILSK1YcInCDM7nWC9hmuAg8A/Arj7O6YntJklt1CQniBEpFacqIrpBeDfgPe4+06AcNbVmpRIDtLeXE9jfbTSoYiITIsTVTH9JrAHeNTMvm1mlxCMpK5JiaTWgRCR2jJhgnD3H7n71cCZwKMEU24sMLNvmtm7pym+GaM7mVIXVxGpKcU0Ug+4+53u/l6CpT+fIejZVDPcPVxJTg3UIlI7TmpSIXdPuvtt7n5JuQKaiQ72jzCczqqBWkRqimadK0Iitw6EEoSI1BAliCLkurh2zVeCEJHaoQRRBI2iFpFapARRhO5kirZ4jNZ4XaVDERGZNkoQRVAPJhGpRUoQRUgkBzUGQkRqjhLEJNw9XElOCUJEaosSxCSOpEYZGMmogVpEao4SxCQSY9N8K0GISG1RgphEQutAiEiNUoKYhEZRi0itUoKYRHdPiub6KHObNAZCRGqLEsQkctN8m9XsUhgiUqOUICaRSKZUvSQiNUkJYhIaRS0itaqsCcLM1pvZi2a208xuLHD+q2a2OXxtN7OevHOZvHP3lTPOifQNjXIkNapR1CJSk2Ll+mAziwLfAC4FEsBTZnafu2/LXePun867/pPAmryPSLn76nLFV4zcNN+qYhKRWlTOJ4h1wE53f9ndR4C7gatOcP01wF1ljOekdWuQnIjUsHImiKXArrz9RHjsOGZ2KrAC+Fne4biZbTSzJ83sfRPcd314zcYDBw6UKOy8gHPrQChBiEgNmimN1FcD97p7Ju/Yqe6+FrgW+JqZnTb+pnB97LXuvrazs7PkQXX3pGiIRehsaSj5Z4uIzHTlTBDdwCl5+13hsUKuZlz1krt3h+8vA49xbPvEtOgOu7hqDISI1KJyJoingFVmtsLM6gmSwHG9kczsTGAe8ETesXlm1hBudwAXAdvG31tuWgdCRGpZ2RKEu6eBTwAPAs8D97j7VjO72cyuzLv0auBud/e8Y2cBG81sC/AocEt+76fpEoyBUIIQkdpUtm6uAO5+P3D/uGM3jdv/YoH7fg6cV87YJpMayXCwf0RdXEWkZs2URuoZZ2wMhJ4gRKRGKUFMIJcgNM2GiNQqJYgJaB0IEal1ShAT6E6miEWMhW3xSociIlIRShAT6O5JsXhunGhEYyBEpDYpQUxA60CISK1TgphAd1LrQIhIbVOCKGAknWVf35CeIESkpilBFLDnSAp3TfMtIrVNCaKAbk3zLSKiBFFIbh2IrrlqgxCR2qUEUUCiJ0XEYNEcjYEQkdqlBFFAdzLFwrY49TH9eUSkdqkELCCRHFQPJhGpeUoQBWgdCBERJYjjpDNZ9hwZUg8mEal5ShDj7OsbJpN1jaIWkZqnBDHO2BgItUGISI1TghhnbB0IVTGJSI1TghhHTxAiIgEliHESyRQdLQ3E66KVDkVEpKJilQ5gplEXV5HaMjo6SiKRYGhoqNKhlFU8Hqerq4u6urqi71GCGKe7J8XZS9oqHYaITJNEIkFrayvLly/HrDpXkHR3Dh06RCKRYMWKFUXfpyqmPNmsBwsFqf1BpGYMDQ3R3t5etckBwMxob28/6ackJYg8B/uHGclkVcUkUmOqOTnkvJ7fUQkiT6JH60CIiOQoQeRJjHVx1ShqEZkePT09/O3f/u1J33fFFVfQ09NT+oDyKEHk0UpyIjLdJkoQ6XT6hPfdf//9zJ07t0xRBdSLKU8iOcjcpjpaGvRnEalFX/rJVrbt7i3pZ569pI0/ee85E56/8cYbeemll1i9ejV1dXXE43HmzZvHCy+8wPbt23nf+97Hrl27GBoa4lOf+hTXX389AMuXL2fjxo309/dz+eWX87a3vY2f//znLF26lB//+Mc0Nk79i66eIPJoDISITLdbbrmF0047jc2bN/PlL3+ZTZs28fWvf53t27cDcPvtt/P000+zceNGbr31Vg4dOnTcZ+zYsYMbbriBrVu3MnfuXH7wgx+UJDZ9Vc7TnUzxhs7mSochIhVyom/602XdunXHjFW49dZb+eEPfwjArl272LFjB+3t7cfcs2LFClavXg3Am970Jl599dWSxKIniJC7k0im1EAtIhXV3Hz0S+pjjz3Gww8/zBNPPMGWLVtYs2ZNwbEMDQ0NY9vRaHTS9otilTVBmNl6M3vRzHaa2Y0Fzn/VzDaHr+1m1pN37sNmtiN8fbiccQIkB0dJjWZUxSQi06q1tZW+vr6C544cOcK8efNoamrihRde4Mknn5zW2MpWxWRmUeAbwKVAAnjKzO5z9225a9z903nXfxJYE27PB/4EWAs48HR4b7Jc8aoHk4hUQnt7OxdddBHnnnsujY2NLFy4cOzc+vXr+da3vsVZZ53FGWecwYUXXjitsZWzDWIdsNPdXwYws7uBq4BtE1x/DUFSALgMeMjdD4f3PgSsB+4qV7Bj60Bomg0RmWZ33nlnweMNDQ088MADBc/l2hk6Ojp47rnnxo7/0R/9UcniKmcV01JgV95+Ijx2HDM7FVgB/Oxk7y2V7nAU9SlaalREBJg5jdRXA/e6e+ZkbjKz681so5ltPHDgwJQCSCRTtDTEaGtUxy4REShvgugGTsnb7wqPFXI1x1YfFXWvu9/m7mvdfW1nZ+eUgk0kgzEQtTBpl4hIMcqZIJ4CVpnZCjOrJ0gC942/yMzOBOYBT+QdfhB4t5nNM7N5wLvDY2XT3ZNS+4OISJ6yJQh3TwOfICjYnwfucfetZnazmV2Zd+nVwN3u7nn3Hgb+lCDJPAXcnGuwLpdEclA9mERE8pS1wt3d7wfuH3fspnH7X5zg3tuB28sWXJ4jqVH6htIaAyEikmemNFJXVLem+RaRCnm9030DfO1rX2NwcLDEER2lBMHRLq56ghCR6TaTE4T6dALduUFyShAite2BG2HvL0v7mYvOg8tvmfB0/nTfl156KQsWLOCee+5heHiY97///XzpS19iYGCAD37wgyQSCTKZDH/8x3/Mvn372L17N+94xzvo6Ojg0UcfLW3cKEEAQRfXeF2E9ub6SociIjXmlltu4bnnnmPz5s1s2LCBe++9l1/84he4O1deeSWPP/44Bw4cYMmSJfzLv/wLEMzRNGfOHL7yla/w6KOP0tHRUZbYlCA42sVVYyBEatwJvulPhw0bNrBhwwbWrFkDQH9/Pzt27ODiiy/mM5/5DJ/73Od4z3vew8UXXzwt8ShBECYITbEhIhXm7nz+85/n4x//+HHnNm3axP33388XvvAFLrnkEm666aYCn1BaaqSGcB0ItT+IyPTLn+77sssu4/bbb6e/vx+A7u5u9u/fz+7du2lqauK6667js5/9LJs2bTru3nKo+SeIwZE0hwdG1INJRCoif7rvyy+/nGuvvZa3vOUtALS0tPDd736XnTt38tnPfpZIJEJdXR3f/OY3Abj++utZv349S5YsKUsjteUNYJ7V1q5d6xs3bjzp+w71D/PFn2zjg2u7uHjV1OZzEpHZ5/nnn+ess86qdBjTotDvamZPu/vaQtfX/BNEe0sDf33NmkqHISIy46gNQkREClKCEJGaVy1V7Sfyen5HJQgRqWnxeJxDhw5VdZJwdw4dOkQ8Hj+p+2q+DUJEaltXVxeJRIKprko508Xjcbq6uk7qHiUIEalpdXV1rFixotJhzEiqYhIRkYKUIEREpCAlCBERKahqRlKb2QHgV1P4iA7gYInCKbfZFCvMrnhnU6wwu+KdTbHC7Ip3KrGe6u4Fp5GomgQxVWa2caLh5jPNbIoVZle8sylWmF3xzqZYYXbFW65YVcUkIiIFKUGIiEhBShBH3VbpAE7CbIoVZle8sylWmF3xzqZYYXbFW5ZY1QYhIiIF6QlCREQKUoIQEZGCaj5BmNl6M3vRzHaa2Y2VjudEzOwUM3vUzLaZ2VYz+1SlY5qMmUXN7Bkz++dKxzIZM5trZvea2Qtm9ryZvaXSMU3EzD4d/ht4zszuMrOTm6azzMzsdjPbb2bP5R2bb2YPmdmO8H1eJWPMmSDWL4f/Dp41sx+a2dwKhniMQvHmnfuMmbmZdZTiZ9V0gjCzKPAN4HLgbOAaMzu7slGdUBr4jLufDVwI3DDD4wX4FPB8pYMo0teBn7r7mcAFzNC4zWwp8N+Bte5+LhAFrq5sVMe5A1g/7tiNwCPuvgp4JNyfCe7g+FgfAs519/OB7cDnpzuoE7iD4+PFzE4B3g28VqofVNMJAlgH7HT3l919BLgbuKrCMU3I3fe4+6Zwu4+gAFta2agmZmZdwG8Af1/pWCZjZnOAtwP/B8DdR9y9p6JBnVgMaDSzGNAE7K5wPMdw98eBw+MOXwV8J9z+DvC+6YxpIoVidfcN7p4Od58ETm6e7DKa4G8L8FXgfwAl63lU6wliKbArbz/BDC5w85nZcmAN8B8VDuVEvkbwDzZb4TiKsQI4APzfsErs782sudJBFeLu3cBfEXxT3AMccfcNlY2qKAvdfU+4vRdYWMlgTsJ/Bh6odBAnYmZXAd3uvqWUn1vrCWJWMrMW4AfAH7h7b6XjKcTM3gPsd/enKx1LkWLAG4FvuvsaYICZUwVyjLDu/iqCpLYEaDaz6yob1cnxoH/9jO9jb2b/i6Bq93uVjmUiZtYE/E/gplJ/dq0niG7glLz9rvDYjGVmdQTJ4Xvu/k+VjucELgKuNLNXCaru3mlm361sSCeUABLunnsiu5cgYcxE7wJecfcD7j4K/BPw1grHVIx9ZrYYIHzfX+F4TsjMPgK8B/htn9kDxk4j+LKwJfz/1gVsMrNFU/3gWk8QTwGrzGyFmdUTNPTdV+GYJmRmRlBH/ry7f6XS8ZyIu3/e3bvcfTnB3/Vn7j5jv+W6+15gl5mdER66BNhWwZBO5DXgQjNrCv9NXMIMbVAf5z7gw+H2h4EfVzCWEzKz9QTVo1e6+2Cl4zkRd/+luy9w9+Xh/7cE8Mbw3/SU1HSCCBuhPgE8SPAf7B5331rZqE7oIuB3CL6Nbw5fV1Q6qCrySeB7ZvYssBr4i8qGU1j4lHMvsAn4JcH/4xk1LYSZ3QU8AZxhZgkz+yhwC3Cpme0geAq6pZIx5kwQ698ArcBD4f+zb1U0yDwTxFuenzWzn5xERKRSavoJQkREJqYEISIiBSlBiIhIQUoQIiJSkBKEiIgUpAQhchLMLJPXxXhzKWcANrPlhWboFKmUWKUDEJllUu6+utJBiEwHPUGIlICZvWpmf2lmvzSzX5jZyvD4cjP7WbiuwCNmtiw8vjBcZ2BL+MpNlRE1s2+Haz1sMLPGiv1SUvOUIEROTuO4KqYP5Z074u7nEYzC/Vp47K+B74TrCnwPuDU8fivwr+5+AcGcT7kR/KuAb7j7OUAP8IGy/jYiJ6CR1CInwcz63b2lwPFXgXe6+8vhhIp73b3dzA4Ci919NDy+x907zOwA0OXuw3mfsRx4KFxQBzP7HFDn7n82Db+ayHH0BCFSOj7B9skYztvOoHZCqSAlCJHS+VDe+xPh9s85uhzobwP/Fm4/AvxXGFu3e850BSlSLH07ETk5jWa2OW//p+6e6+o6L5wJdhi4Jjz2SYJV6j5LsGLd74XHPwXcFs7EmSFIFnsQmUHUBiFSAmEbxFp3P1jpWERKRVVMIiJSkJ4gRESkID1BiIhIQUoQIiJSkBKEiIgUpAQhIiIFKUGIiEhB/x8+EBCEstdnHgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "\n",
    "pyplot.plot(history.history['accuracy'], label='train') \n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Accuracy')\n",
    "pyplot.legend(loc='lower right')\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "053416be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot \n",
    "\n",
    "pyplot.plot(history.history['loss'], label='train') \n",
    "pyplot.plot(history.history['val_loss'], label='test') \n",
    "\n",
    "pyplot.xlabel('Epoch')\n",
    "pyplot.ylabel('Loss')\n",
    "pyplot.legend(loc='lower right')\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d54cc02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder inference\n",
    "latent_dim=500#load the model\n",
    "model = models.load_model(\"s2s\")\n",
    " \n",
    "# Construct encoder model from the output of 6 layer i.e.last LSTM layer\n",
    "en_outputs,state_h_enc,state_c_enc = model.layers[6].output\n",
    "en_states=[state_h_enc,state_c_enc]\n",
    "# Add input and state from the layer.\n",
    "en_model = Model(model.input[0],[en_outputs]+en_states)\n",
    "\n",
    "# Decoder inference\n",
    "# Create Input object for hidden and cell state for decoder\n",
    "# Shape of layer with hidden or latent dimension\n",
    "dec_state_input_h = Input(shape=(latent_dim,))\n",
    "dec_state_input_c = Input(shape=(latent_dim,))\n",
    "dec_hidden_state_input = Input(shape=(max_in_len,latent_dim))\n",
    " \n",
    "# Get the embeddings and input layer from the model\n",
    "dec_inputs = model.input[1]\n",
    "dec_emb_layer = model.layers[5]\n",
    "dec_lstm = model.layers[7]\n",
    "dec_embedding= dec_emb_layer(dec_inputs)\n",
    " \n",
    "# Add input and initialize LSTM layer with encoder LSTM states.\n",
    "dec_outputs2, state_h2, state_c2 = dec_lstm(dec_embedding, initial_state=[dec_state_input_h,dec_state_input_c])\n",
    "\n",
    "# Attention layer\n",
    "attention = model.layers[8]\n",
    "attn_out2 = attention([dec_outputs2,dec_hidden_state_input])\n",
    " \n",
    "merge2 = Concatenate(axis=-1)([dec_outputs2, attn_out2])\n",
    "\n",
    "# Dense layer\n",
    "dec_dense = model.layers[10]\n",
    "dec_outputs2 = dec_dense(merge2)\n",
    " \n",
    "# Finally define the Model Class\n",
    "dec_model = Model(\n",
    "[dec_inputs] + [dec_hidden_state_input,dec_state_input_h,dec_state_input_c],\n",
    "[dec_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c83e9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# pickle.dump(en_model, open('./en_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b569558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with a key as index and value as words.\n",
    "reverse_target_word_index = tr_tokenizer.index_word\n",
    "reverse_source_word_index = in_tokenizer.index_word\n",
    "target_word_index = tr_tokenizer.word_index\n",
    "reverse_target_word_index[0]=' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "831ffece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence_naive(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    # Get the encoder output and states by passing the input sequence\n",
    "    en_out, en_h, en_c= en_model.predict(input_seq)\n",
    " \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    # Target sequence with initial word as 'start'\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    " \n",
    "    # If the iteration reaches the end of text than it will be stop the iteration\n",
    "    stop_condition = False\n",
    "    \n",
    "    # Append every predicted word in decoded sentence\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition: \n",
    "        # Get predicted output, hidden and cell state.\n",
    "        output_words, dec_h, dec_c= dec_model.predict([target_seq] + [en_out,en_h, en_c])\n",
    "        \n",
    "        # Get the index and from the dictionary get the word for that index.\n",
    "        word_index = np.argmax(output_words[0, -1, :])\n",
    "        text_word = reverse_target_word_index[word_index]\n",
    "        print(\"text_word\", text_word)\n",
    "        decoded_sentence += text_word +\" \"\n",
    "        \n",
    "        # Exit condition: either hit max length or find a stop word or last word.\n",
    "        if text_word == \"end\" or len(decoded_sentence) > max_tr_len:\n",
    "            stop_condition = True\n",
    "            \n",
    "        # Update target sequence to the current word index.\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = word_index\n",
    "        en_h, en_c = dec_h, dec_c\n",
    "    # Return the decoded sentence\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bcca5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_step(model, beam_size, target_seq, en_out, en_h, en_c):\n",
    "        \n",
    "    output_words, dec_h, dec_c = model.predict([target_seq] + [en_out, en_h, en_c])\n",
    "    # Get indexes of all the top probabilities\n",
    "    word_indexes = np.argpartition(output_words[0, -1, :], -beam_size)[-beam_size:]\n",
    "\n",
    "    return word_indexes[:beam_size], np.log(output_words[0, -1, word_indexes]), dec_h, dec_c\n",
    "\n",
    "def decode_sequence_beamsearch(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    # Get the encoder output and states by passing the input sequence\n",
    "    en_out, en_h, en_c = en_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    \n",
    "    # Target sequence with initial word as 'start'\n",
    "    target_seq[0, 0] = target_word_index['start']\n",
    "   \n",
    "    past_targets = [target_seq]\n",
    "    past_hs = [en_h]\n",
    "    past_cs = [en_c]\n",
    " \n",
    "    # If the iteration reaches the end of text than it will be stop the iteration\n",
    "    stop_condition = False\n",
    "    \n",
    "    beam_indices = []\n",
    "    beam_probs = []\n",
    "    beam_words = []\n",
    "    \n",
    "    BSIZE = 1\n",
    "    cpt = True\n",
    "    \n",
    "    while not stop_condition: \n",
    "        idxes_beam = []\n",
    "        pbs_beam = []\n",
    "        for past_target, past_h, past_c in zip(past_targets, past_hs, past_cs):\n",
    "            # for each couple of (past_targets, past_hs, past_cs) predict the best word along with BSIZE (3) words after it (we are keeping indexes)\n",
    "            if (cpt):\n",
    "                NEWBSIZE = BSIZE\n",
    "                idxes, pbs, h, c = beam_step(dec_model, NEWBSIZE, past_target, en_out, past_hs, past_cs)\n",
    "                cpt = False\n",
    "            else:\n",
    "                NEWBSIZE = BSIZE*BSIZE\n",
    "                idxes, pbs, h, c = beam_step(dec_model, NEWBSIZE, past_target, en_out, past_hs, past_cs)\n",
    "            # add the indexes of those words to the end of idxes_beam\n",
    "            idxes_beam.extend(idxes)\n",
    "            # add the proba of those words to the list of probs \n",
    "            pbs_beam.extend(pbs)\n",
    "            # The append() method adds a single element to the end of a list, and the extend() method adds multiple items.\n",
    "          \n",
    "        \n",
    "        # choose the max proba among the maxes\n",
    "        word_indexes = np.argpartition(pbs_beam, -BSIZE)[-BSIZE:]\n",
    "        # np.divmod(x, y) is equivalent to (x // y, x % y)  \n",
    "        idx_div, idx_mod = np.divmod(word_indexes, BSIZE)\n",
    "        beam_indices.append(idx_div)\n",
    "        beam_words.append(np.array(idxes_beam)[word_indexes])\n",
    "        if len(beam_probs) == 0:\n",
    "            beam_probs.append(np.array(pbs_beam)[word_indexes])\n",
    "\n",
    "        else:\n",
    "            beam_probs.append(np.array(pbs_beam)[word_indexes] + beam_probs[-1][idx_div]) \n",
    "\n",
    "        word_index = beam_words[-1][np.argmax(beam_probs[-1])]\n",
    "        text_word = reverse_target_word_index[word_index]\n",
    "        \n",
    "        # Exit condition: either hit max length or find a stop word or last word.\n",
    "        if text_word == \"end\" or len(beam_words) == max_tr_len:\n",
    "            print (\"Exit condition\")\n",
    "            stop_condition = True\n",
    "            \n",
    "        # Update target sequence to the current word index.\n",
    "        past_targets = []\n",
    "        past_hs = h\n",
    "        past_cs = c\n",
    "\n",
    "        for i in range(BSIZE):\n",
    "            target_seq = np.zeros((1, 1))\n",
    "            target_seq[0, 0] = beam_words[-1][i]\n",
    "            past_targets.append(target_seq)\n",
    "            \n",
    "    \n",
    "    words = []\n",
    "    \n",
    "    i = len(beam_probs) - 1\n",
    "    j = np.argmax(beam_probs[i])\n",
    "    \n",
    "    while i > -1:\n",
    "        word_index = beam_words[i][j]\n",
    "        text_word = reverse_target_word_index[word_index]\n",
    "        words.insert(0, text_word)\n",
    "        j = beam_indices[i][j]\n",
    "        i -= 1\n",
    "        \n",
    "    # Return the decoded sentence\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ff3a61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text : collecting commercial information for example online shopping cart information purchase history\n",
      "1/1 [==============================] - 1s 774ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "text_word using\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "text_word information\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "text_word end\n",
      "\n",
      "Predicted summary: using information  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inpt_txt = \"whatsapp must receive or collect some information to operate provide improve understand customize support and market our services including when you install access or use our services the types of information we receive and collect depend on how you use our services we require certain information to deliver our services and without this we will not be able to provide our services to you for example you must provide your mobile phone number to create an account to use our service\"\n",
    "# inpt_txt = \"we may collect your personal data when you register for or use our services such as when you create an account make a payment or make a purchase on a merchants website\"\n",
    "inpt_txt = \"collecting commercial information for example online shopping cart information purchase history\"\n",
    "print(\"text :\",inpt_txt)\n",
    "inpt_txt = clean(inpt_txt)\n",
    "# inpt_txt = ' '.join(inpt_txt)\n",
    "inp_x= in_tokenizer.texts_to_sequences([inpt_txt]) \n",
    "inp_x= pad_sequences(inp_x,  maxlen=max_in_len, padding='post')\n",
    " \n",
    "summary=decode_sequence_naive(inp_x.reshape(1,max_in_len))\n",
    "if 'end' in summary :\n",
    "    summary=summary.replace('end','')\n",
    "print(\"\\nPredicted summary:\",summary);print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9389afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "#After executing this we will be having two file in same directory model.json & model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46e9531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(in_tokenizer, open('./in_tokenizer.pkl', 'wb'))\n",
    "pickle.dump(tr_tokenizer, open('./tr_tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "100829c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x1265fd23ac0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_tokenizer = pickle.load(open('in_tokenizer.pkl', 'rb'))\n",
    "in_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec550484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.text.Tokenizer at 0x126045c5970>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_tokenizer = pickle.load(open('tr_tokenizer.pkl', 'rb'))\n",
    "tr_tokenizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
